{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":104884,"sourceType":"datasetVersion","datasetId":54339}],"dockerImageVersionId":30528,"isInternetEnabled":true,"language":"python","sourceType":"script","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-03-05T18:07:49.167939Z\",\"iopub.execute_input\":\"2024-03-05T18:07:49.168214Z\",\"iopub.status.idle\":\"2024-03-05T18:07:58.839288Z\",\"shell.execute_reply.started\":\"2024-03-05T18:07:49.168189Z\",\"shell.execute_reply\":\"2024-03-05T18:07:58.838315Z\"}}\n# import system libs \nimport os\nimport time\nimport shutil\nimport itertools\n\n# import data handling tools \nimport cv2\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nsns.set_style('darkgrid')\nimport matplotlib.pyplot as plt\n# import Deep learning Libraries\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Activation, Dropout, BatchNormalization\nfrom tensorflow.keras.models import Model, load_model, Sequential\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.optimizers import Adam, Adamax\nfrom tensorflow.keras import regularizers\nfrom tensorflow.keras.metrics import categorical_crossentropy\n\n# Ignore Warnings\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nprint ('modules loaded')\n\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-03-05T18:07:58.841203Z\",\"iopub.execute_input\":\"2024-03-05T18:07:58.841966Z\",\"iopub.status.idle\":\"2024-03-05T18:08:03.754752Z\",\"shell.execute_reply.started\":\"2024-03-05T18:07:58.841929Z\",\"shell.execute_reply\":\"2024-03-05T18:08:03.753792Z\"}}\ndata_dir = '/kaggle/input/skin-cancer-mnist-ham10000/hmnist_28_28_RGB.csv'\ndata = pd.read_csv(data_dir)\ndata.head()\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-03-05T18:08:03.755994Z\",\"iopub.execute_input\":\"2024-03-05T18:08:03.756354Z\",\"iopub.status.idle\":\"2024-03-05T18:08:03.821221Z\",\"shell.execute_reply.started\":\"2024-03-05T18:08:03.756319Z\",\"shell.execute_reply\":\"2024-03-05T18:08:03.820069Z\"}}\nLabel = data[\"label\"]\nData = data.drop(columns=[\"label\"])\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-03-05T18:08:03.824275Z\",\"iopub.execute_input\":\"2024-03-05T18:08:03.824664Z\",\"iopub.status.idle\":\"2024-03-05T18:08:03.839414Z\",\"shell.execute_reply.started\":\"2024-03-05T18:08:03.824630Z\",\"shell.execute_reply\":\"2024-03-05T18:08:03.838559Z\"}}\ndata[\"label\"].value_counts()\n\n# %% [markdown]\n# We have imbalance in the data\n\n# %% [markdown]\n# **Handling imbalanced datasets**\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-03-05T18:08:03.840638Z\",\"iopub.execute_input\":\"2024-03-05T18:08:03.841003Z\",\"iopub.status.idle\":\"2024-03-05T18:08:07.238775Z\",\"shell.execute_reply.started\":\"2024-03-05T18:08:03.840970Z\",\"shell.execute_reply\":\"2024-03-05T18:08:07.237769Z\"}}\nfrom imblearn.over_sampling import RandomOverSampler \n\noversample = RandomOverSampler()\nData, Label  = oversample.fit_resample(Data, Label)\nData = np.array(Data).reshape(-1, 28, 28, 3)\nprint('Shape of Data :', Data.shape)\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-03-05T18:08:07.240142Z\",\"iopub.execute_input\":\"2024-03-05T18:08:07.241013Z\",\"iopub.status.idle\":\"2024-03-05T18:08:07.247765Z\",\"shell.execute_reply.started\":\"2024-03-05T18:08:07.240974Z\",\"shell.execute_reply\":\"2024-03-05T18:08:07.246866Z\"}}\nLabel = np.array(Label)\nLabel\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-03-05T18:08:07.249052Z\",\"iopub.execute_input\":\"2024-03-05T18:08:07.249421Z\",\"iopub.status.idle\":\"2024-03-05T18:08:07.259628Z\",\"shell.execute_reply.started\":\"2024-03-05T18:08:07.249387Z\",\"shell.execute_reply\":\"2024-03-05T18:08:07.258774Z\"}}\nclasses = {4: ('nv', ' melanocytic nevi'),\n           6: ('mel', 'melanoma'),\n           2 :('bkl', 'benign keratosis-like lesions'), \n           1:('bcc' , ' basal cell carcinoma'),\n           5: ('vasc', ' pyogenic granulomas and hemorrhage'),\n           0: ('akiec', 'Actinic keratoses and intraepithelial carcinomae'),\n           3: ('df', 'dermatofibroma')}\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-03-05T18:08:07.260784Z\",\"iopub.execute_input\":\"2024-03-05T18:08:07.261097Z\",\"iopub.status.idle\":\"2024-03-05T18:08:08.499885Z\",\"shell.execute_reply.started\":\"2024-03-05T18:08:07.261071Z\",\"shell.execute_reply\":\"2024-03-05T18:08:08.498847Z\"}}\nfrom sklearn.model_selection import train_test_split\n\nX_train , X_test , y_train , y_test = train_test_split(Data , Label , test_size = 0.25 , random_state = 49)\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-03-05T18:08:08.501008Z\",\"iopub.execute_input\":\"2024-03-05T18:08:08.501295Z\",\"iopub.status.idle\":\"2024-03-05T18:08:08.506649Z\",\"shell.execute_reply.started\":\"2024-03-05T18:08:08.501270Z\",\"shell.execute_reply\":\"2024-03-05T18:08:08.505564Z\"}}\nprint(X_train.shape)\nprint(y_train.shape)\nprint(X_test.shape)\nprint(y_test.shape)\n\n# %% [markdown]\n# **Convert labels to categorical types**\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-03-05T18:08:08.511435Z\",\"iopub.execute_input\":\"2024-03-05T18:08:08.511763Z\",\"iopub.status.idle\":\"2024-03-05T18:08:08.521100Z\",\"shell.execute_reply.started\":\"2024-03-05T18:08:08.511728Z\",\"shell.execute_reply\":\"2024-03-05T18:08:08.520109Z\"}}\nfrom keras.utils.np_utils import to_categorical\n\ny_train = to_categorical(y_train)\ny_test = to_categorical(y_test)\n\n# %% [markdown]\n# **Create Image Data Generation**\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-03-05T18:08:08.522143Z\",\"iopub.execute_input\":\"2024-03-05T18:08:08.522391Z\",\"iopub.status.idle\":\"2024-03-05T18:08:08.530731Z\",\"shell.execute_reply.started\":\"2024-03-05T18:08:08.522368Z\",\"shell.execute_reply\":\"2024-03-05T18:08:08.529854Z\"}}\ndatagen = ImageDataGenerator(rescale=(1./255)\n                             ,rotation_range=10\n                             ,zoom_range = 0.1\n                             ,width_shift_range=0.1\n                             ,height_shift_range=0.1)\n\ntestgen = ImageDataGenerator(rescale=(1./255))\n\n# %% [markdown]\n# **Create ReduceLROnPlateau to learning rate reduction**\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-03-05T18:08:08.531816Z\",\"iopub.execute_input\":\"2024-03-05T18:08:08.532086Z\",\"iopub.status.idle\":\"2024-03-05T18:08:08.542346Z\",\"shell.execute_reply.started\":\"2024-03-05T18:08:08.532063Z\",\"shell.execute_reply\":\"2024-03-05T18:08:08.541482Z\"}}\nfrom keras.callbacks import ReduceLROnPlateau\n\nlearning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy'\n                                            , patience = 2\n                                            , verbose=1\n                                            ,factor=0.5\n                                            , min_lr=0.00001)\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-03-05T18:08:08.543662Z\",\"iopub.execute_input\":\"2024-03-05T18:08:08.544124Z\",\"iopub.status.idle\":\"2024-03-05T18:08:11.296528Z\",\"shell.execute_reply.started\":\"2024-03-05T18:08:08.544093Z\",\"shell.execute_reply\":\"2024-03-05T18:08:11.295501Z\"}}\nmodel = keras.models.Sequential()\n\n# Create Model Structure\nmodel.add(keras.layers.Input(shape=[28, 28, 3]))\nmodel.add(keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal'))\nmodel.add(keras.layers.MaxPooling2D())\nmodel.add(keras.layers.BatchNormalization())\n\nmodel.add(keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal'))\nmodel.add(keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal'))\nmodel.add(keras.layers.MaxPooling2D())\nmodel.add(keras.layers.BatchNormalization())\nmodel.add(keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal'))\nmodel.add(keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal'))\nmodel.add(keras.layers.MaxPooling2D())\nmodel.add(keras.layers.BatchNormalization())\n\nmodel.add(keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal'))\nmodel.add(keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal'))\nmodel.add(keras.layers.MaxPooling2D())\n\nmodel.add(keras.layers.Flatten())\nmodel.add(keras.layers.Dropout(rate=0.2))\nmodel.add(keras.layers.Dense(units=256, activation='relu', kernel_initializer='he_normal'))\nmodel.add(keras.layers.BatchNormalization())\n\nmodel.add(keras.layers.Dense(units=128, activation='relu', kernel_initializer='he_normal'))\nmodel.add(keras.layers.BatchNormalization())\n\nmodel.add(keras.layers.Dense(units=64, activation='relu', kernel_initializer='he_normal'))\nmodel.add(keras.layers.BatchNormalization())\n\nmodel.add(keras.layers.Dense(units=32, activation='relu', kernel_initializer='he_normal', kernel_regularizer=keras.regularizers.L1L2()))\nmodel.add(keras.layers.BatchNormalization())\n\nmodel.add(keras.layers.Dense(units=7, activation='softmax', kernel_initializer='glorot_uniform', name='classifier'))\nmodel.compile(Adamax(learning_rate= 0.001), loss= 'categorical_crossentropy', metrics= ['accuracy'])\n\nmodel.summary()\n\n\n\n# %% [markdown]\n# **Training model**\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-03-05T18:08:11.298020Z\",\"iopub.execute_input\":\"2024-03-05T18:08:11.298325Z\",\"iopub.status.idle\":\"2024-03-05T18:09:44.866301Z\",\"shell.execute_reply.started\":\"2024-03-05T18:08:11.298299Z\",\"shell.execute_reply\":\"2024-03-05T18:09:44.865297Z\"}}\nhistory = model.fit(X_train ,\n                    y_train ,\n                    epochs=25 ,\n                    batch_size=128,\n                    validation_data=(X_test , y_test) ,\n                    callbacks=[learning_rate_reduction])\n\n# %% [markdown]\n# **Show training history**\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-03-05T18:09:44.867941Z\",\"iopub.execute_input\":\"2024-03-05T18:09:44.870298Z\",\"iopub.status.idle\":\"2024-03-05T18:09:44.877662Z\",\"shell.execute_reply.started\":\"2024-03-05T18:09:44.870267Z\",\"shell.execute_reply\":\"2024-03-05T18:09:44.876704Z\"}}\nfrom tensorflow import keras\n# Define or load your CNN model\ncnn_model = keras.models.Sequential()\n# Add layers and configure the model as needed\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-03-05T18:09:44.878827Z\",\"iopub.execute_input\":\"2024-03-05T18:09:44.879184Z\",\"iopub.status.idle\":\"2024-03-05T18:09:44.888666Z\",\"shell.execute_reply.started\":\"2024-03-05T18:09:44.879150Z\",\"shell.execute_reply\":\"2024-03-05T18:09:44.887838Z\"}}\nimport joblib\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-03-05T18:09:44.891569Z\",\"iopub.execute_input\":\"2024-03-05T18:09:44.891817Z\",\"iopub.status.idle\":\"2024-03-05T18:09:44.907785Z\",\"shell.execute_reply.started\":\"2024-03-05T18:09:44.891796Z\",\"shell.execute_reply\":\"2024-03-05T18:09:44.906798Z\"}}\njoblib.dump(cnn_model, 'cnn_model_skin.joblib')\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-03-05T18:09:44.909029Z\",\"iopub.execute_input\":\"2024-03-05T18:09:44.909319Z\",\"iopub.status.idle\":\"2024-03-05T18:09:44.914414Z\",\"shell.execute_reply.started\":\"2024-03-05T18:09:44.909294Z\",\"shell.execute_reply\":\"2024-03-05T18:09:44.913706Z\"}}\nfrom sklearn.ensemble import RandomForestClassifier\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-03-05T18:09:44.915575Z\",\"iopub.execute_input\":\"2024-03-05T18:09:44.915926Z\",\"iopub.status.idle\":\"2024-03-05T18:09:44.927284Z\",\"shell.execute_reply.started\":\"2024-03-05T18:09:44.915894Z\",\"shell.execute_reply\":\"2024-03-05T18:09:44.926543Z\"}}\nloaded_cnn_model = joblib.load('cnn_model_skin.joblib')\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-03-05T18:09:44.928292Z\",\"iopub.execute_input\":\"2024-03-05T18:09:44.928723Z\",\"iopub.status.idle\":\"2024-03-05T18:09:51.561449Z\",\"shell.execute_reply.started\":\"2024-03-05T18:09:44.928697Z\",\"shell.execute_reply\":\"2024-03-05T18:09:51.560558Z\"}}\nX_train_features = loaded_cnn_model.predict(X_train)\nX_test_features = loaded_cnn_model.predict(X_test)\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-03-05T18:09:51.562935Z\",\"iopub.execute_input\":\"2024-03-05T18:09:51.563236Z\",\"iopub.status.idle\":\"2024-03-05T18:09:51.567781Z\",\"shell.execute_reply.started\":\"2024-03-05T18:09:51.563209Z\",\"shell.execute_reply\":\"2024-03-05T18:09:51.566833Z\"}}\nX_train_features_flat = X_train_features.reshape(X_train_features.shape[0], -1)\nX_test_features_flat = X_test_features.reshape(X_test_features.shape[0], -1)\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-03-05T18:09:51.568991Z\",\"iopub.execute_input\":\"2024-03-05T18:09:51.569295Z\",\"iopub.status.idle\":\"2024-03-05T18:12:18.446679Z\",\"shell.execute_reply.started\":\"2024-03-05T18:09:51.569271Z\",\"shell.execute_reply\":\"2024-03-05T18:12:18.445647Z\"}}\nrf_classifier = RandomForestClassifier(n_estimators=100, random_state=0)\nrf_classifier.fit(X_train_features_flat, y_train)\n\n# %% [markdown]\n# \n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-03-05T18:12:18.448089Z\",\"iopub.execute_input\":\"2024-03-05T18:12:18.448457Z\",\"iopub.status.idle\":\"2024-03-05T18:12:19.422883Z\",\"shell.execute_reply.started\":\"2024-03-05T18:12:18.448423Z\",\"shell.execute_reply\":\"2024-03-05T18:12:19.422046Z\"}}\n# Make predictions using the trained Random Forest classifier\ny_pred = rf_classifier.predict(X_test_features_flat)\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-03-05T18:12:19.424152Z\",\"iopub.execute_input\":\"2024-03-05T18:12:19.424772Z\",\"iopub.status.idle\":\"2024-03-05T18:12:19.435477Z\",\"shell.execute_reply.started\":\"2024-03-05T18:12:19.424734Z\",\"shell.execute_reply\":\"2024-03-05T18:12:19.434383Z\"}}\ndef plot_training(hist):\n    tr_acc = hist.history['accuracy']\n    tr_loss = hist.history['loss']\n    val_acc = hist.history['val_accuracy']\n    val_loss = hist.history['val_loss']\n    index_loss = np.argmin(val_loss)\n    val_lowest = val_loss[index_loss]\n    index_acc = np.argmax(val_acc)\n    acc_highest = val_acc[index_acc]\n\n    plt.figure(figsize= (20, 8))\n    plt.style.use('fivethirtyeight')\n    Epochs = [i+1 for i in range(len(tr_acc))]\n    loss_label = f'best epoch= {str(index_loss + 1)}'\n    acc_label = f'best epoch= {str(index_acc + 1)}'\n    \n    plt.subplot(1, 2, 1)\n    plt.plot(Epochs, tr_loss, 'r', label= 'Training loss')\n    plt.plot(Epochs, val_loss, 'g', label= 'Validation loss')\n    plt.scatter(index_loss + 1, val_lowest, s= 150, c= 'blue', label= loss_label)\n    plt.title('Training and Validation Loss')\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.legend()\n    \n    plt.subplot(1, 2, 2)\n    plt.plot(Epochs, tr_acc, 'r', label= 'Training Accuracy')\n    plt.plot(Epochs, val_acc, 'g', label= 'Validation Accuracy')\n    plt.scatter(index_acc + 1 , acc_highest, s= 150, c= 'blue', label= acc_label)\n    plt.title('Training and Validation Accuracy')\n    plt.xlabel('Epochs')\n    plt.ylabel('Accuracy')\n    plt.legend()\n    \n    plt.tight_layout\n    plt.show()\n    \n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-03-05T18:12:19.436793Z\",\"iopub.execute_input\":\"2024-03-05T18:12:19.437053Z\",\"iopub.status.idle\":\"2024-03-05T18:12:20.246953Z\",\"shell.execute_reply.started\":\"2024-03-05T18:12:19.437030Z\",\"shell.execute_reply\":\"2024-03-05T18:12:20.246037Z\"}}\nplot_training(history)\n\n# %% [markdown]\n# # Model Evaluation\n\n# %% [code]\n\n\n# %% [code]\n\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-03-05T18:12:20.248191Z\",\"iopub.execute_input\":\"2024-03-05T18:12:20.248486Z\",\"iopub.status.idle\":\"2024-03-05T18:12:27.172255Z\",\"shell.execute_reply.started\":\"2024-03-05T18:12:20.248458Z\",\"shell.execute_reply\":\"2024-03-05T18:12:27.171303Z\"}}\ntrain_score = model.evaluate(X_train, y_train, verbose= 1)\ntest_score = model.evaluate(X_test, y_test, verbose= 1)\n\nprint(\"Train Loss: \", train_score[0])\nprint(\"Train Accuracy: \", train_score[1])\nprint('-' * 20)\nprint(\"Test Loss: \", test_score[0])\nprint(\"Test Accuracy: \", test_score[1])\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-03-05T18:12:27.173407Z\",\"iopub.execute_input\":\"2024-03-05T18:12:27.173726Z\",\"iopub.status.idle\":\"2024-03-05T18:12:27.178752Z\",\"shell.execute_reply.started\":\"2024-03-05T18:12:27.173699Z\",\"shell.execute_reply\":\"2024-03-05T18:12:27.177895Z\"}}\ny_true = np.array(y_test)\n\ny_pred = np.argmax(y_pred , axis=1)\ny_true = np.argmax(y_true , axis=1)\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-03-05T18:12:27.184198Z\",\"iopub.execute_input\":\"2024-03-05T18:12:27.184469Z\",\"iopub.status.idle\":\"2024-03-05T18:12:27.190789Z\",\"shell.execute_reply.started\":\"2024-03-05T18:12:27.184445Z\",\"shell.execute_reply\":\"2024-03-05T18:12:27.189919Z\"}}\nfrom sklearn.metrics import accuracy_score, classification_report\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-03-05T18:12:27.191811Z\",\"iopub.execute_input\":\"2024-03-05T18:12:27.192050Z\",\"iopub.status.idle\":\"2024-03-05T18:12:27.233145Z\",\"shell.execute_reply.started\":\"2024-03-05T18:12:27.192028Z\",\"shell.execute_reply\":\"2024-03-05T18:12:27.232467Z\"}}\naccuracy = accuracy_score(y_true, y_pred)\nreport = classification_report(y_true, y_pred)\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-03-05T18:12:27.234102Z\",\"iopub.execute_input\":\"2024-03-05T18:12:27.234368Z\",\"iopub.status.idle\":\"2024-03-05T18:12:27.239261Z\",\"shell.execute_reply.started\":\"2024-03-05T18:12:27.234344Z\",\"shell.execute_reply\":\"2024-03-05T18:12:27.238358Z\"}}\nprint(\"Accuracy:\", accuracy)\nprint(\"Classification Report:\\n\", report)\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-03-05T18:12:27.240414Z\",\"iopub.execute_input\":\"2024-03-05T18:12:27.240740Z\",\"iopub.status.idle\":\"2024-03-05T18:12:27.279846Z\",\"shell.execute_reply.started\":\"2024-03-05T18:12:27.240712Z\",\"shell.execute_reply\":\"2024-03-05T18:12:27.278960Z\"}}\nprint(classification_report(y_true, y_pred))\n\n# %% [markdown]\n# **Create classes labels**\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-03-05T18:12:27.280907Z\",\"iopub.execute_input\":\"2024-03-05T18:12:27.281668Z\",\"iopub.status.idle\":\"2024-03-05T18:12:27.286497Z\",\"shell.execute_reply.started\":\"2024-03-05T18:12:27.281626Z\",\"shell.execute_reply\":\"2024-03-05T18:12:27.285582Z\"}}\nclasses_labels = []\nfor key in classes.keys():\n    classes_labels.append(key)\n\nprint(classes_labels)\n\n# %% [markdown]\n# **Confussion Matrix**\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-03-05T18:12:27.287959Z\",\"iopub.execute_input\":\"2024-03-05T18:12:27.288575Z\",\"iopub.status.idle\":\"2024-03-05T18:12:27.872043Z\",\"shell.execute_reply.started\":\"2024-03-05T18:12:27.288540Z\",\"shell.execute_reply\":\"2024-03-05T18:12:27.871080Z\"}}\n# Confusion matrix\ncm = cm = confusion_matrix(y_true, y_pred, labels=classes_labels)\n\nplt.figure(figsize= (10, 10))\nplt.imshow(cm, interpolation= 'nearest', cmap= plt.cm.Blues)\nplt.title('Confusion Matrix')\nplt.colorbar()\n\ntick_marks = np.arange(len(classes))\nplt.xticks(tick_marks, classes, rotation= 45)\nplt.yticks(tick_marks, classes)\n\n\nthresh = cm.max() / 2.\nfor i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n    plt.text(j, i, cm[i, j], horizontalalignment= 'center', color= 'white' if cm[i, j] > thresh else 'black')\n\nplt.tight_layout()\nplt.ylabel('True Label')\nplt.xlabel('Predicted Label')\n\nplt.show()\n\n\n\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-03-05T18:12:27.873239Z\",\"iopub.execute_input\":\"2024-03-05T18:12:27.873620Z\",\"iopub.status.idle\":\"2024-03-05T18:12:27.878642Z\",\"shell.execute_reply.started\":\"2024-03-05T18:12:27.873581Z\",\"shell.execute_reply\":\"2024-03-05T18:12:27.877665Z\"}}\n# from sklearn.metrics import confusion_matrix, classification_report\n\n# classes = range(7)\n    \n# # Y_true (true labels) and Y_pred_classes (predicted labels)\n# Y_pred = model.predict(X_test)\n# Y_pred_classes = np.argmax(Y_pred, axis=1)\n# Y_true = np.argmax(y_test, axis=1)\n\n# # Compute the confusion matrix\n# confusion_mtx = confusion_matrix(Y_true, Y_pred_classes)\n\n# # Plot the confusion matrix with the new colorscale\n# plot_confusion_matrix(confusion_mtx, classes=classes, normalize=False)\n\n# report = classification_report(Y_true, Y_pred_classes)\n# print(f\"Classification Report for <<CNN RF>> : \")\n# print(report)\n\n# %% [code]\n\n\n# %% [markdown]\n# **Tflite file**\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-03-05T18:12:27.879771Z\",\"iopub.execute_input\":\"2024-03-05T18:12:27.880035Z\",\"iopub.status.idle\":\"2024-03-05T18:12:36.126614Z\",\"shell.execute_reply.started\":\"2024-03-05T18:12:27.879999Z\",\"shell.execute_reply\":\"2024-03-05T18:12:36.125594Z\"}}\nconverter = tf.lite.TFLiteConverter.from_keras_model(model)\ntflite_model = converter.convert()\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-03-05T18:12:36.127642Z\",\"iopub.execute_input\":\"2024-03-05T18:12:36.127928Z\",\"iopub.status.idle\":\"2024-03-05T18:12:36.137861Z\",\"shell.execute_reply.started\":\"2024-03-05T18:12:36.127904Z\",\"shell.execute_reply\":\"2024-03-05T18:12:36.136933Z\"}}\nwith tf.io.gfile.GFile('model__v1.tflite', 'wb') as f:\n  f.write(tflite_model)\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-03-05T18:12:36.139118Z\",\"iopub.execute_input\":\"2024-03-05T18:12:36.139504Z\",\"iopub.status.idle\":\"2024-03-05T18:12:36.202331Z\",\"shell.execute_reply.started\":\"2024-03-05T18:12:36.139452Z\",\"shell.execute_reply\":\"2024-03-05T18:12:36.201325Z\"}}\ninterpreter = tf.lite.Interpreter(\"model__v1.tflite\")\nprint(interpreter.get_input_details())\n\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-03-05T18:20:23.683181Z\",\"iopub.execute_input\":\"2024-03-05T18:20:23.683565Z\",\"iopub.status.idle\":\"2024-03-05T18:20:23.692751Z\",\"shell.execute_reply.started\":\"2024-03-05T18:20:23.683532Z\",\"shell.execute_reply\":\"2024-03-05T18:20:23.691694Z\"}}\n#helper function to evaluate tflite model on the test dataset\nfrom statistics import mean\ntest_images = X_test\ntest_labels = classes_labels\ndef eval_model(interpreter):\n  input_index = interpreter.get_input_details()[0][\"index\"]\n  output_index = interpreter.get_output_details()[0][\"index\"]\n\n  # Run predictions on every image in the \"test\" dataset.\n  prediction_digits = []\n  for i, test_image in enumerate(test_images):\n    if i % 1000 == 0:\n      print('Evaluated on {n} results so far.'.format(n=i))\n    # Pre-processing: add batch dimension and convert to float32 to match with\n    # the model's input data format.\n    test_image = np.expand_dims(test_image, axis=0).astype(np.float32)\n    interpreter.set_tensor(input_index, test_image)\n\n    # Run inference.\n    interpreter.invoke()\n\n    # Post-processing: remove batch dimension and find the digit with highest\n    # probability.\n    output = interpreter.tensor(output_index)\n    digit = np.argmax(output()[0])\n    prediction_digits.append(digit)\n    output_details = interpreter.get_output_details()\n  print(output_details)  \n  print('\\n')\n  # Compare prediction results with ground truth labels to calculate accuracy.\n  prediction_digits = np.array(prediction_digits)\n#   accuracy = [(prediction_digits == test_labels)].mean()\n#   print([(prediction_digits == test_labels)])\n#   accuracy = mean([(prediction_digits == test_labels)]) #problem\n\n#   accuracy = (prediction_digits == test_labels).mean()\n  accuracy = np.mean(prediction_digits == test_labels) #problem\n  return accuracy\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-03-05T18:20:35.050840Z\",\"iopub.execute_input\":\"2024-03-05T18:20:35.051250Z\",\"iopub.status.idle\":\"2024-03-05T18:20:45.843305Z\",\"shell.execute_reply.started\":\"2024-03-05T18:20:35.051215Z\",\"shell.execute_reply\":\"2024-03-05T18:20:45.842312Z\"}}\n\ninterpreter.allocate_tensors()\n\ntest_accuracy = eval_model(interpreter)\n\n\n# print('Baseline TF test accuracy:', baseline_model_accuracy)\n# print('Clustered test accuracy:', model__v1)\nprint(' TFLite test_accuracy:', test_accuracy)\n\n# %% [raw]\n# \n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-03-05T18:20:51.112345Z\",\"iopub.execute_input\":\"2024-03-05T18:20:51.112740Z\",\"iopub.status.idle\":\"2024-03-05T18:21:01.671988Z\",\"shell.execute_reply.started\":\"2024-03-05T18:20:51.112706Z\",\"shell.execute_reply\":\"2024-03-05T18:21:01.671013Z\"}}\n\n# Passing the Integer Quantized TF Lite model to the Interpreter.\ninterpreter = tf.lite.Interpreter('/kaggle/working/model__v1.tflite')\n\n# Allocating tensors.\ninterpreter.allocate_tensors()\n\n# Evaluating the model on the test images.\n# test_accuracy_integer = evaluate(interpreter)\ntest_accuracy_integer = eval_model(interpreter)\n# Printing the test accuracy for the Integer Quantized TFLite model and the baseline Keras model.\nprint('Integer Quantized TFLite Model Test Accuracy:', test_accuracy_integer*100)\n# print('Baseline Keras Model Test Accuracy:', baseline_model_accuracy*100)\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-03-05T18:12:36.236920Z\",\"iopub.execute_input\":\"2024-03-05T18:12:36.237176Z\",\"iopub.status.idle\":\"2024-03-05T18:12:44.297377Z\",\"shell.execute_reply.started\":\"2024-03-05T18:12:36.237153Z\",\"shell.execute_reply\":\"2024-03-05T18:12:44.296325Z\"}}\n\n\n# # Passing the Keras model to the TF Lite Converter.\n# converter = tf.lite.TFLiteConverter.from_keras_model(model)\n \n# # Using float-16 quantization.\n# converter.optimizations = [tf.lite.Optimize.DEFAULT]\n# converter.target_spec.supported_types = [tf.float16]\n \n# # Converting the model.\n# tflite_fp16_model = converter.convert()\n \n# # Saving the model.\n# with open('/kaggle/working/model__v1.tflite', 'wb') as f:\n#   f.write(tflite_fp16_model)\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-03-05T18:12:44.298916Z\",\"iopub.execute_input\":\"2024-03-05T18:12:44.299210Z\",\"iopub.status.idle\":\"2024-03-05T18:12:44.307038Z\",\"shell.execute_reply.started\":\"2024-03-05T18:12:44.299184Z\",\"shell.execute_reply\":\"2024-03-05T18:12:44.306005Z\"}}\n# from statistics import mean\n# #Function for evaluating TF Lite Model over Test Images\n# test_images = X_test\n# def evaluate(interpreter):\n#   prediction= []\n#   input_index = interpreter.get_input_details()[0][\"index\"]\n#   output_index = interpreter.get_output_details()[0][\"index\"]\n#   input_format = interpreter.get_output_details()[0]['dtype']\n  \n#   for i, test_image in enumerate(test_images):\n#     if i % 100 == 0:\n#       print('Evaluated on {n} results so far.'.format(n=i))\n#     test_image = np.expand_dims(test_image, axis=0).astype(input_format)\n#     interpreter.set_tensor(input_index, test_image)\n \n#     # Run inference.\n#     interpreter.invoke()\n#     output = interpreter.tensor(output_index)\n#     predicted_label = np.argmax(output()[0])\n#     prediction.append(predicted_label)\n    \n#   print('\\n')\n#   # Comparing prediction results with ground truth labels to calculate accuracy.\n#   prediction = np.array(prediction)\n#   accuracy = np.mean([(prediction == classes_labels)])\n#   return accuracy\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-03-05T18:18:26.206628Z\",\"iopub.execute_input\":\"2024-03-05T18:18:26.207023Z\",\"iopub.status.idle\":\"2024-03-05T18:18:26.211544Z\",\"shell.execute_reply.started\":\"2024-03-05T18:18:26.206992Z\",\"shell.execute_reply\":\"2024-03-05T18:18:26.210582Z\"}}\n# # Passing the FP-16 TF Lite model to the interpreter.\n# interpreter = tf.lite.Interpreter('/kaggle/working/model__v1.tflite')\n# # Allocating tensors.\n# interpreter.allocate_tensors()\n# # Evaluating the model on the test dataset.\n# test_accuracy = evaluate(interpreter)\n# print('Float 16 Quantized TFLite Model Test Accuracy:', test_accuracy*100)\n# #print('Baseline Keras Model Test Accuracy:', baseline_model_accuracy*100)\n\n# %% [code]\n","metadata":{"_uuid":"b9056925-0377-4938-91e0-9de8e45387ff","_cell_guid":"f191a99c-0d08-4349-9d15-c57c385a5b1b","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]}]}